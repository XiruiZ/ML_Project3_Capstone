{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker==1.72.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.72.0)\n",
      "Requirement already satisfied: boto3>=1.14.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.17.76)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.19.5)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==0.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (0.1.4)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.15.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (3.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (20.9)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker==1.72.0) (1.5.3)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.76 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.14.12->sagemaker==1.72.0) (1.20.76)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.76->boto3>=1.14.12->sagemaker==1.72.0) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.76->boto3>=1.14.12->sagemaker==1.72.0) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker==1.72.0) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->sagemaker==1.72.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker==1.72.0) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker==1.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "valid = test = pd.read_csv('data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, use original variables\n",
    "train = train.drop(['stays_in_night', 'total'],1) \n",
    "test = test.drop(['stays_in_night', 'total'],1) \n",
    "valid = valid.drop(['stays_in_night', 'total'],1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and Y#\n",
    "train_Y = train['is_canceled']\n",
    "train_X = train.drop(['is_canceled'],1)\n",
    "\n",
    "test_Y = test['is_canceled']\n",
    "test_X = test.drop(['is_canceled'],1)\n",
    "\n",
    "valid_Y = valid['is_canceled']\n",
    "valid_X = valid.drop(['is_canceled'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/xgboost'\n",
    "if not os.path.exists(data_dir):  \n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save data\n",
    "test_X.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "pd.concat([train_Y, train_X], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)\n",
    "pd.concat([valid_Y, valid_X], axis=1).to_csv(os.path.join(data_dir, 'valid.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use XGBoost to cunstruct a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session() # Store the current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix (which folder will we use)\n",
    "prefix = 'captsone-xgboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "valid_location = session.upload_data(os.path.join(data_dir, 'valid.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#role and container\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(region, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    train_instance_count=1,                  # How many compute instances\n",
    "                                    train_instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=4, # change these set_hyperparameters to see the influence\n",
    "                        eta=0.1,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        num_class = 2,\n",
    "                        objective='multi:softmax', # try different models\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29 13:57:28 Starting - Starting the training job...\n",
      "2021-05-29 13:57:30 Starting - Launching requested ML instances......\n",
      "2021-05-29 13:58:38 Starting - Preparing the instances for training.........\n",
      "2021-05-29 14:00:25 Downloading - Downloading input data...\n",
      "2021-05-29 14:00:55 Training - Training image download completed. Training in progress.\n",
      "2021-05-29 14:00:55 Uploading - Uploading generated training model.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:00:54:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:00:54:INFO] File size need to be processed in the node: 0.08mb. Available memory size in the node: 8413.74mb\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:00:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:00:54] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:00:54] 1467x13 matrix with 19071 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:00:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:00:54] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:00:54] 315x13 matrix with 4095 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.226994#011validation-merror:0.215873\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-merror hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-merror:0.224267#011validation-merror:0.250794\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-merror:0.206544#011validation-merror:0.619048\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[3]#011train-merror:0.184731#011validation-merror:0.634921\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.167689#011validation-merror:0.609524\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[5]#011train-merror:0.163599#011validation-merror:0.6\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[6]#011train-merror:0.164281#011validation-merror:0.596825\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[7]#011train-merror:0.164281#011validation-merror:0.615873\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[8]#011train-merror:0.164963#011validation-merror:0.619048\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[9]#011train-merror:0.164963#011validation-merror:0.622222\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:00:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[10]#011train-merror:0.162918#011validation-merror:0.622222\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.226994#011validation-merror:0.215873\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-29 14:01:02 Completed - Training job completed\n",
      "Training seconds: 37\n",
      "Billable seconds: 37\n"
     ]
    }
   ],
   "source": [
    "## Fit the XGBoost model\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=valid_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "## Testing the model\n",
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:10:17:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:10:17:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:10:17 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:10:17:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:10:17:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\n",
      "\u001b[34m[2021-05-29:14:10:21:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:10:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-05-29:14:10:21:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2021-05-29:14:10:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-05-29T14:10:21.257:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-445297930402/xgboost-2021-05-29-14-05-31-244/test.csv.out to data/xgboost/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "predictions = [round(num) for num in predictions.squeeze().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(predictions, test_Y):\n",
    "    tp = fp = fn = tn = 0\n",
    "    \n",
    "    for i in range(len(test_Y)):\n",
    "        # true positive\n",
    "        if test_Y[i]==predictions[i]==1: tp = tp+1\n",
    "        # true negative\n",
    "        elif test_Y[i]==predictions[i]==0: tn = tn+1\n",
    "        # false negative\n",
    "        elif test_Y[i]==1: fn = fn+1\n",
    "        # false positive\n",
    "        else: fp = fp+1\n",
    "    \n",
    "    return tp, fp, fn, tn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true-positive: 0\n",
      "accuracy: 0.7841269841269841\n"
     ]
    }
   ],
   "source": [
    "# How many canceled rooms are predicted correctly?\n",
    "tp, _, _, _ = results(predictions, test_Y)\n",
    "print('true-positive:', tp)\n",
    "print('accuracy:', accuracy_score(test_Y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tre prediction results are not good. True-Positive is always 0. True to transform the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In second attempt, use the added variables\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "valid = test = pd.read_csv('data/valid.csv')\n",
    "\n",
    "\n",
    "train = train.drop(['stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies'],1) \n",
    "test = test.drop(['stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies'],1)\n",
    "valid = valid.drop(['stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies'],1)\n",
    "\n",
    "\n",
    "train_Y = train['is_canceled']\n",
    "train_X = train.drop(['is_canceled'],1)\n",
    "\n",
    "test_Y = test['is_canceled']\n",
    "test_X = test.drop(['is_canceled'],1)\n",
    "\n",
    "valid_Y = valid['is_canceled']\n",
    "valid_X = valid.drop(['is_canceled'],1)\n",
    "\n",
    "\n",
    "test_X.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "pd.concat([train_Y, train_X], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)\n",
    "pd.concat([valid_Y, valid_X], axis=1).to_csv(os.path.join(data_dir, 'valid.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29 14:18:26 Starting - Starting the training job...\n",
      "2021-05-29 14:18:28 Starting - Launching requested ML instances......\n",
      "2021-05-29 14:19:38 Starting - Preparing the instances for training......\n",
      "2021-05-29 14:20:49 Downloading - Downloading input data...\n",
      "2021-05-29 14:21:20 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:21:42:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:21:42:INFO] File size need to be processed in the node: 0.07mb. Available memory size in the node: 8430.09mb\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:21:42:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:21:42] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:21:42] 1467x10 matrix with 14670 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:21:42:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:21:42] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:21:42] 315x10 matrix with 3150 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.225631#011validation-merror:0.215873\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-merror hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-merror:0.226994#011validation-merror:0.215873\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-merror:0.182686#011validation-merror:0.606349\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[3]#011train-merror:0.177914#011validation-merror:0.6\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.176551#011validation-merror:0.406349\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[5]#011train-merror:0.179959#011validation-merror:0.412698\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[6]#011train-merror:0.173824#011validation-merror:0.580952\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[7]#011train-merror:0.178596#011validation-merror:0.406349\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[8]#011train-merror:0.173142#011validation-merror:0.593651\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[9]#011train-merror:0.169734#011validation-merror:0.596825\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:21:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[10]#011train-merror:0.167689#011validation-merror:0.609524\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.225631#011validation-merror:0.215873\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-29 14:21:53 Uploading - Uploading generated training model\n",
      "2021-05-29 14:21:53 Completed - Training job completed\n",
      "Training seconds: 64\n",
      "Billable seconds: 64\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "valid_location = session.upload_data(os.path.join(data_dir, 'valid.csv'), key_prefix=prefix)\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "container = get_image_uri(region, 'xgboost')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container, \n",
    "                                    role,                                  \n",
    "                                    train_instance_count=1,                 \n",
    "                                    train_instance_type='ml.m4.xlarge',    \n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=4, \n",
    "                        eta=0.1,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        num_class = 2,\n",
    "                        objective='multi:softmax', \n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=80)\n",
    "\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=valid_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:27:31:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:27:31 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:27:31:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:27:31:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:27:31:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:27:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:27:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-05-29T14:27:35.316:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-445297930402/xgboost-2021-05-29-14-22-39-898/test.csv.out to data/xgboost/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "predictions = [round(num) for num in predictions.squeeze().values]\n",
    "tp, _, _, _ = results(predictions, test_Y)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7841269841269841\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', accuracy_score(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resultes are not good at all. Try to simplify the factors.\n",
    "# This time, I use only 'hotel', 'lead_time', 'arrival_date_week_number', 'reserved_room_type', 'customer_type', 'adr', 'stays_in_night', 'total'\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "valid = test = pd.read_csv('data/valid.csv')\n",
    "\n",
    "\n",
    "keep_variables = ['hotel', 'is_canceled', 'lead_time', 'arrival_date_week_number', 'reserved_room_type', \n",
    "                  'customer_type', 'adr', 'stays_in_night', 'total']\n",
    "train = train[keep_variables]\n",
    "test= test[keep_variables]\n",
    "valid = valid[keep_variables]\n",
    "\n",
    "\n",
    "train_Y = train['is_canceled']\n",
    "train_X = train.drop(['is_canceled'],1)\n",
    "\n",
    "test_Y = test['is_canceled']\n",
    "test_X = test.drop(['is_canceled'],1)\n",
    "\n",
    "valid_Y = valid['is_canceled']\n",
    "valid_X = valid.drop(['is_canceled'],1)\n",
    "\n",
    "\n",
    "test_X.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "pd.concat([train_Y, train_X], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)\n",
    "pd.concat([valid_Y, valid_X], axis=1).to_csv(os.path.join(data_dir, 'valid.csv'), header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29 14:34:47 Starting - Starting the training job...\n",
      "2021-05-29 14:34:49 Starting - Launching requested ML instances......\n",
      "2021-05-29 14:36:15 Starting - Preparing the instances for training.........\n",
      "2021-05-29 14:37:33 Downloading - Downloading input data...\n",
      "2021-05-29 14:38:03 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:38:26:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:38:26:INFO] File size need to be processed in the node: 0.07mb. Available memory size in the node: 8428.23mb\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:38:26:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:38:26] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:38:26] 1467x8 matrix with 11736 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:38:26:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:38:26] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:38:26] 315x8 matrix with 2520 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-merror:0.218814#011validation-merror:0.64127\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-merror hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-merror:0.218132#011validation-merror:0.653968\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-merror:0.216087#011validation-merror:0.644444\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[3]#011train-merror:0.216087#011validation-merror:0.657143\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.194274#011validation-merror:0.612698\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[5]#011train-merror:0.190866#011validation-merror:0.631746\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[6]#011train-merror:0.194274#011validation-merror:0.634921\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[7]#011train-merror:0.194956#011validation-merror:0.650794\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[8]#011train-merror:0.179959#011validation-merror:0.653968\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[9]#011train-merror:0.179277#011validation-merror:0.653968\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[10]#011train-merror:0.182686#011validation-merror:0.653968\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[11]#011train-merror:0.182686#011validation-merror:0.644444\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[12]#011train-merror:0.180641#011validation-merror:0.634921\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[13]#011train-merror:0.175869#011validation-merror:0.647619\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14:38:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14]#011train-merror:0.173824#011validation-merror:0.644444\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[4]#011train-merror:0.194274#011validation-merror:0.612698\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-29 14:38:38 Uploading - Uploading generated training model\n",
      "2021-05-29 14:38:38 Completed - Training job completed\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "valid_location = session.upload_data(os.path.join(data_dir, 'valid.csv'), key_prefix=prefix)\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "container = get_image_uri(region, 'xgboost')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container, \n",
    "                                    role,                                 \n",
    "                                    train_instance_count=1,                  \n",
    "                                    train_instance_type='ml.m4.xlarge',   \n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=4, \n",
    "                        eta=0.1,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        num_class = 2,\n",
    "                        objective='multi:softmax', \n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=80)\n",
    "\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=valid_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:48:02:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:48:02:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:48:02:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-05-29 14:48:02 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:48:02:INFO] Model loaded successfully for worker : 24\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:48:05:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:14:48:05:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-05-29T14:48:05.915:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-445297930402/xgboost-2021-05-29-14-43-00-144/test.csv.out to data/xgboost/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "predictions = [round(num) for num in predictions.squeeze().values]\n",
    "tp, _, _, _ = results(predictions, test_Y)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3873015873015873\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', accuracy_score(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
